{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd2f26c",
   "metadata": {},
   "source": [
    "### Loading all the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988d0b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document content:\n",
      "Python is a high-level, interpreted programming language known for its readability and concise syntax, which makes it ideal for beginners and professionals alike. It supports multiple paradigms, including object-oriented, functional, and procedural programming. With a vast standard library and rich ecosystem of third-party packages (like NumPy, Pandas, Django, and FastAPI), Python excels in domains such as data science, web development, automation, scripting, and AI/ML. Its strong community, cross-platform support, and ease of integration with other languages and systems make it a versatile choice for rapid development and production-ready applications.\n",
      "Python is a high-level, interpreted programming language known for its readability and concise syntax, which makes it ideal for beginners and professionals alike. It supports multiple paradigms, including object-oriented, functional, and procedural programming. With a vast standard library and rich ecosystem of third-party packages (like NumPy, Pandas, Django, and FastAPI), Python excels in domains such as data science, web development, automation, scripting, and AI/ML. Its strong community, cro\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=\"../datas/\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document content:\\n{documents[0].page_content}\")\n",
    "print(documents[0].page_content[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1faa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 chunks\n",
      "\n",
      "First chunk content:\n",
      "Deep learning is a subset of machine learning that uses multi-layered neural networks to automatically learn hierarchical representations from data. A neural network is composed of interconnected nodes (“neurons”) organized in layers—input, hidden, and output—that transform inputs through learned weights and nonlinear activations. By training on large datasets with optimization methods like stochastic gradient descent, these models capture complex patterns for tasks such as image recognition,\n",
      "Content Deep learning is a subset of machine learning that uses multi-layered neural networks to automatically learn hierarchical representations from data. A neural network is composed of interconnected nodes (“neurons”) organized in layers—input, hidden, and output—that transform inputs through learned weights and nonlinear activations. By training on large datasets with optimization methods like stochastic gradient descent, these models capture complex patterns for tasks such as image recognition,\n",
      "Metadata {'source': '../datas/doc_2.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Initializing test Spillter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "print(f\"\\nFirst chunk content:\\n{chunks[0].page_content}\")\n",
    "print(f\"Content {chunks[0].page_content[:500]}\")  # Print first 500 characters\n",
    "print(f\"Metadata {chunks[0].metadata}\")  # Print metadata of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab118ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a0a50",
   "metadata": {},
   "source": [
    "### Loading the ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945c4867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 3 vectors\n",
      "Persisted at: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "\n",
    "persist_directory = \"./chroma_db\"\n",
    "client = chromadb.PersistentClient(\n",
    "    path=persist_directory,\n",
    ")\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=OpenAIEmbeddingFunction(api_key=os.getenv(\"OPENAI_API_KEY\"), model_name=\"text-embedding-3-small\"),\n",
    ")\n",
    "collection.add(\n",
    "    ids=[str(i) for i in range(len(documents))],\n",
    "    documents=[\n",
    "        document.page_content\n",
    "        for document in documents\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {collection.count()} vectors\")\n",
    "print(f\"Persisted at: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5517cd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Machine learning fundamentals center on teaching computers to learn patterns from data and make predictions without being explicitly programmed. Core steps include collecting and cleaning data, selecting features, choosing a model (e.g., linear regression, decision trees, neural networks), and training it by minimizing a loss function with algorithms like gradient descent. We evaluate performance with metrics such as accuracy, precision/recall, RMSE, or AUC on validation/test sets and guard against overfitting with techniques like regularization and cross-validation. Understanding bias-variance trade-offs, data leakage, and proper model deployment/monitoring is essential for building reliable, generalizable systems.', 'Deep learning is a subset of machine learning that uses multi-layered neural networks to automatically learn hierarchical representations from data. A neural network is composed of interconnected nodes (“neurons”) organized in layers—input, hidden, and output—that transform inputs through learned weights and nonlinear activations. By training on large datasets with optimization methods like stochastic gradient descent, these models capture complex patterns for tasks such as image recognition, natural language understanding, and speech synthesis. Depth (many layers) enables the network to learn increasingly abstract features, often outperforming traditional methods when ample data and compute are available.', 'Python is a high-level, interpreted programming language known for its readability and concise syntax, which makes it ideal for beginners and professionals alike. It supports multiple paradigms, including object-oriented, functional, and procedural programming. With a vast standard library and rich ecosystem of third-party packages (like NumPy, Pandas, Django, and FastAPI), Python excels in domains such as data science, web development, automation, scripting, and AI/ML. Its strong community, cross-platform support, and ease of integration with other languages and systems make it a versatile choice for rapid development and production-ready applications.']]\n",
      "[[0.9171087741851807, 1.0240767002105713, 1.6350317001342773]]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Types of Machine Learning?\"\n",
    "\n",
    "similer_docs = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3,\n",
    ")\n",
    "print(similer_docs[\"documents\"])\n",
    "print(similer_docs[\"distances\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
