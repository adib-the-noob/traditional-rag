{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd2f26c",
   "metadata": {},
   "source": [
    "### Loading all the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=\"../datas/\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document content:\\n{documents[0].page_content}\")\n",
    "print(documents[0].page_content[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1faa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 chunks\n",
      "\n",
      "First chunk content:\n",
      "Deep learning is a subset of machine learning that uses multi-layered neural networks to automatically learn hierarchical representations from data. A neural network is composed of interconnected nodes (“neurons”) organized in layers—input, hidden, and output—that transform inputs through learned weights and nonlinear activations. By training on large datasets with optimization methods like stochastic gradient descent, these models capture complex patterns for tasks such as image recognition,\n",
      "Content Deep learning is a subset of machine learning that uses multi-layered neural networks to automatically learn hierarchical representations from data. A neural network is composed of interconnected nodes (“neurons”) organized in layers—input, hidden, and output—that transform inputs through learned weights and nonlinear activations. By training on large datasets with optimization methods like stochastic gradient descent, these models capture complex patterns for tasks such as image recognition,\n",
      "Metadata {'source': '../datas/doc_2.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Initializing test Spillter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "print(f\"\\nFirst chunk content:\\n{chunks[0].page_content}\")\n",
    "print(f\"Content {chunks[0].page_content[:500]}\")  # Print first 500 characters\n",
    "print(f\"Metadata {chunks[0].metadata}\")  # Print metadata of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab118ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a0a50",
   "metadata": {},
   "source": [
    "### Loading the ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "945c4867",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected document to be a str, got page_content='Deep learning is a subset of machine learning that uses multi-layered neural networks to automatically learn hierarchical representations from data. A neural network is composed of interconnected nodes (“neurons”) organized in layers—input, hidden, and output—that transform inputs through learned weights and nonlinear activations. By training on large datasets with optimization methods like stochastic gradient descent, these models capture complex patterns for tasks such as image recognition, natural language understanding, and speech synthesis. Depth (many layers) enables the network to learn increasingly abstract features, often outperforming traditional methods when ample data and compute are available.' metadata={'source': '../datas/doc_2.txt'} in add.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m client = chromadb.PersistentClient(\n\u001b[32m     11\u001b[39m     path=persist_directory,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m collection = client.get_or_create_collection(\n\u001b[32m     15\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mmy_collection\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     embedding_function=OpenAIEmbeddingFunction(api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m), model_name=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-3-small\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVector store created with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection.count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m vectors\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPersisted at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpersist_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UdemyRAG-KNaik/.venv/lib/python3.13/site-packages/chromadb/api/models/Collection.py:84\u001b[39m, in \u001b[36mCollection.add\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     51\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     62\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \n\u001b[32m     82\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     add_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._add(\n\u001b[32m     94\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m     95\u001b[39m         ids=add_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    102\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UdemyRAG-KNaik/.venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:95\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UdemyRAG-KNaik/.venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:219\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_add_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    209\u001b[39m add_records = normalize_insert_record_set(\n\u001b[32m    210\u001b[39m     ids=ids,\n\u001b[32m    211\u001b[39m     embeddings=embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    215\u001b[39m     uris=uris,\n\u001b[32m    216\u001b[39m )\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m validate_record_set_contains_any(record_set=add_records, contains_any={\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Prepare\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UdemyRAG-KNaik/.venv/lib/python3.13/site-packages/chromadb/api/types.py:313\u001b[39m, in \u001b[36mvalidate_insert_record_set\u001b[39m\u001b[34m(record_set)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03mValidates the InsertRecordSet, ensuring that all fields are of the right type and length.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m _validate_record_set_length_consistency(record_set)\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[43mvalidate_base_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m validate_ids(record_set[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[33m\"\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UdemyRAG-KNaik/.venv/lib/python3.13/site-packages/chromadb/api/types.py:297\u001b[39m, in \u001b[36mvalidate_base_record_set\u001b[39m\u001b[34m(record_set)\u001b[39m\n\u001b[32m    295\u001b[39m     validate_embeddings(embeddings=record_set[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[43mvalidate_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# If embeddings are present, some documents can be None\u001b[39;49;00m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnullable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    303\u001b[39m     validate_images(images=record_set[\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UdemyRAG-KNaik/.venv/lib/python3.13/site-packages/chromadb/api/types.py:1138\u001b[39m, in \u001b[36mvalidate_documents\u001b[39m\u001b[34m(documents, nullable)\u001b[39m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_document(document):\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected document to be a str, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Expected document to be a str, got page_content='Deep learning is a subset of machine learning that uses multi-layered neural networks to automatically learn hierarchical representations from data. A neural network is composed of interconnected nodes (“neurons”) organized in layers—input, hidden, and output—that transform inputs through learned weights and nonlinear activations. By training on large datasets with optimization methods like stochastic gradient descent, these models capture complex patterns for tasks such as image recognition, natural language understanding, and speech synthesis. Depth (many layers) enables the network to learn increasingly abstract features, often outperforming traditional methods when ample data and compute are available.' metadata={'source': '../datas/doc_2.txt'} in add."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "\n",
    "persist_directory = \"./chroma_db\"\n",
    "client = chromadb.PersistentClient(\n",
    "    path=persist_directory,\n",
    ")\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=OpenAIEmbeddingFunction(api_key=os.getenv(\"OPENAI_API_KEY\"), model_name=\"text-embedding-3-small\"),\n",
    ")\n",
    "collection.add(\n",
    "    ids=[str(i) for i in range(len(documents))],\n",
    "    documents=documents,\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {collection.count()} vectors\")\n",
    "print(f\"Persisted at: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5517cd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [[]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[]],\n",
       " 'distances': [[]]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Types of Machine Learning?\"\n",
    "\n",
    "similer_docst = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=2,\n",
    ")\n",
    "similer_docst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemyrag-knaik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
